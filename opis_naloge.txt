V seminarski nalogi bomo primerjali tri različne algoritme
spodbujevalnega učenjana na treh različnih nalogah.

Za izvedbo eksperimentov bomo uporabili knjižnico stable-baselines (algoritmi)
in knjižnico gym (igre za testiranje algoritmov).

Algoritmi:
- Proximal policy optimisation (PPO)
- Asynchronous actor critic (A2C)
- Soft actor critic (SAC)

Igre:
- BipedalWalker (https://gym.openai.com/envs/BipedalWalkerHardcore-v2/)
- MountainCarContinuous-v0 (https://gym.openai.com/envs/CartPole-v1/)
- Pong (https://gym.openai.com/envs/Pong-v0/)

Izvedli bomo predprocesiranje vhodnih podatkov ter prilagodili algoritme
za opravljanje posameznih nalog.

Algoritme bomo primerjali po:
  - Številu korakov (timesteps) po katerih skonvergirajo. (sample complexity)
  - Robustnost na random seed (samo na enem tasku, za vsak algoritem)
  - Kakovost naučenih algoritov (glede na končni rezultat igre)
  (razvidno iz prvega grafa o stevilu korakov)
